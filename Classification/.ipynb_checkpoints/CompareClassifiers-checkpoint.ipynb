{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fc7dbe",
   "metadata": {},
   "source": [
    "### Parts of this code taken and modified from:  \n",
    "Location: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py  \n",
    "Code source: Gaël Varoquaux  \n",
    "              Andreas Müller  \n",
    "Modified for documentation by Jaques Grobler  \n",
    "License: BSD 3 clause  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146852de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ee5039",
   "metadata": {},
   "source": [
    "## Lets evaluate the Linear SVM, RBF SVM, and K-nn on synthetic data sets\n",
    "Observe how easy it is to use different classifiers with the same code because of the framework the ```sklearn``` library uses to impement these classification algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1)\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c8c3f",
   "metadata": {},
   "source": [
    "### Generate fake data to test the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08bd421",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbab2e0",
   "metadata": {},
   "source": [
    "### Visualize Our Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757889e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(17,6))\n",
    "for ii,ds in enumerate(datasets):\n",
    "    X, y = ds\n",
    "    ax[ii].scatter(X[y.astype(bool),0],X[y.astype(bool),1],s=100)\n",
    "    ax[ii].scatter(X[~y.astype(bool),0],X[~y.astype(bool),1],s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149affa0",
   "metadata": {},
   "source": [
    "###  Visualize Z-score normalization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755033f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(17,6))\n",
    "for ii,ds in enumerate(datasets):\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    ax[ii].scatter(X[y.astype(bool),0],X[y.astype(bool),1],s=100)\n",
    "    ax[ii].scatter(X[~y.astype(bool),0],X[~y.astype(bool),1],s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e3701",
   "metadata": {},
   "source": [
    "### Split data into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3912cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets[0]\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=.4, random_state=42)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596aebbe",
   "metadata": {},
   "source": [
    "### Lets test a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c080949",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_num = 2\n",
    "clf = classifiers[clf_num]\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "score_train = clf.score(X_train,y_train) * 100\n",
    "score_test = clf.score(X_test,y_test) * 100\n",
    "\n",
    "print('The ' + names[clf_num] + ' algorithm had a test accuracy of ' + str(round(score_test*10)/10) + '% and a Training accuracy of ' + str(round(score_train*10)/10) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14cf5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions from last time to visualize classifier boundaries\n",
    "def make_meshgrid(X, ngrid=100, slack=0.2):\n",
    "    if len(X.shape) > 2:\n",
    "        warnings.warn('Grid visualization only work for 2D or less!')\n",
    "    xmin, xmax = X[:, 0].min(),  X[:, 0].max()\n",
    "    ymin, ymax = X[:, 1].min(),  X[:, 1].max()\n",
    "    \n",
    "    # Apply some slack so points are are not near the edge\n",
    "    xmin *= 1 - np.sign(xmin) * slack\n",
    "    xmax *= 1 + np.sign(xmax) * slack\n",
    "    ymin *= 1 - np.sign(ymin) * slack\n",
    "    ymax *= 1 + np.sign(ymax) * slack\n",
    "    \n",
    "    dx = (xmax - xmin) / ngrid\n",
    "    dy = (ymax - ymin) / ngrid\n",
    "    x = np.arange(xmin, xmax, dx)\n",
    "    y = np.arange(ymin, ymax, dy)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    return (xx, yy)\n",
    "\n",
    "\n",
    "def plot_decision(xx, yy, clf, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_train = clf.predict(X_train)\n",
    "y_predicted_test = clf.predict(X_test)\n",
    "\n",
    "\n",
    "xx,yy = make_meshgrid(X_train)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X[y.astype(bool),0],X[y.astype(bool),1],s=100,color = 'Tab:orange')\n",
    "plt.scatter(X[~y.astype(bool),0],X[~y.astype(bool),1],s=100, color='Tab:blue')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plot_decision(xx,yy,clf,cmap='seismic',alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a84913",
   "metadata": {},
   "source": [
    "### Lets evaluate the algorithms all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30987555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "figure = plt.figure(figsize=(20, 9))\n",
    "i = 1\n",
    "h = .02  # step size in the mesh\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)   #Normalize Features\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)   #Split data into test and training sets\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='k')\n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "               edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "        # Plot the testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   edgecolors='k', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfa592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
